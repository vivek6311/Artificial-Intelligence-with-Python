{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNwn6hc2rIUAhBJ2jqLDsUg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivek6311/Artificial-Intelligence-with-Python/blob/master/Vivek_Kumar_Lab1_TLP23_ML_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Lab 2\n",
        "\n",
        "## Assignment 2 (Deadline : 22/01/2023 11:59PM)\n",
        "\n",
        "Total Points : 25\n",
        "\n",
        "Your answers must be entered in LMS by midnight of the day it is due. \n",
        "\n",
        "If the question requires a textual response, you can create a PDF and upload that. \n",
        "\n",
        "The PDF might be generated from MS-WORD, LATEX, the image of a hand- written response, or using any other mechanism. \n",
        "\n",
        "Code must be uploaded and may require demonstration to the TA. \n",
        "\n",
        "Numbers in the parentheses indicate points allocated to the question. \n",
        "\n",
        "**Naming Convention**: FirstName_LastName_Lab1_TLP23.ipynb"
      ],
      "metadata": {
        "id": "ErGALREPranW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q1\n",
        "We want to design a system that can help a visually impaired person\n",
        "know what is around them. At present, they use a “white cane” that\n",
        "is used to tap and feel is there is an obstacle. We want to use machine learning to make life slightly better for them. However, given the\n",
        "limitation of time we will consider a subset, though a core part of the\n",
        "problem.\n",
        "\n",
        "The posture we will adopt is that the mobile phone camera can acquire\n",
        "images at some periodic intervals or when the individual wants to know\n",
        "what is in the field of view of where the camera is being pointed. Assume that there are only 10 objects that are there in the world (there\n",
        "is no class which is “everything else”) and the field of view may contain\n",
        "one of those 10 objects.\n",
        "\n",
        "The image is fed into a network that you have to design that can\n",
        "recognize what the object is. Hopefully, a speech synthesizer can then\n",
        "announce it to the individual but we will not concern ourselves with\n",
        "the speech synthesis part.\n",
        "\n",
        "Use the CIFAR-10 dataset https://www.cs.toronto.edu/~kriz/cifar.\n",
        "html. This dataset has 10 objects and each image has an object. In\n",
        "a real system we will have to contend with segmentation problem but\n",
        "let us assume that step has been done for us."
      ],
      "metadata": {
        "id": "1lMIJFmnrzH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Design a FCNN using\n",
        " \n",
        "*   a single layer **(7 points)**\n",
        "\n",
        "*   multiple layers in lower dimension, and **(7 points)**\n",
        "\n",
        "*   a deep FCNN **(7 points)**\n",
        "\n",
        "\n",
        "that can recognize the object (the category can be fed into a speech synthesizer\n",
        "that can announce the object in the filed of view but that is not part of\n",
        "the scope). Report the 5-fold cross validation accuracy for the third deep FCNN  and comment\n",
        "on some practical difficulties that you may face in implement this on a\n",
        "mobile phone **(4 points)**"
      ],
      "metadata": {
        "id": "1HP3LmYUr16G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A Single Layer FCNN"
      ],
      "metadata": {
        "id": "mIFAGf04sMi9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "73cD0TPykPb3"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "txHkmSrCkTXV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "8dhjXOz-kTTu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=x_train.shape[1:]))\n",
        "model.add(Dense(units=10, activation='softmax'))"
      ],
      "metadata": {
        "id": "uKgDQ2jHkTQH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "nq2xReHIkTE0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=32, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMkamAvAke9h",
        "outputId": "b35b0b20-1a6c-407d-d21f-6ce7912474d1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.9644 - accuracy: 0.3170 - val_loss: 1.8059 - val_accuracy: 0.3817\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.8753 - accuracy: 0.3568 - val_loss: 1.8581 - val_accuracy: 0.3462\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.8462 - accuracy: 0.3651 - val_loss: 1.9134 - val_accuracy: 0.3306\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.8411 - accuracy: 0.3696 - val_loss: 1.8273 - val_accuracy: 0.3594\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.8366 - accuracy: 0.3705 - val_loss: 1.9340 - val_accuracy: 0.3424\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.8231 - accuracy: 0.3762 - val_loss: 1.9274 - val_accuracy: 0.3587\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.8202 - accuracy: 0.3805 - val_loss: 1.8821 - val_accuracy: 0.3479\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.8080 - accuracy: 0.3839 - val_loss: 1.8632 - val_accuracy: 0.3725\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.8026 - accuracy: 0.3866 - val_loss: 1.8140 - val_accuracy: 0.3647\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.8005 - accuracy: 0.3846 - val_loss: 1.9062 - val_accuracy: 0.3531\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.7958 - accuracy: 0.3900 - val_loss: 1.7560 - val_accuracy: 0.3960\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.7917 - accuracy: 0.3884 - val_loss: 1.8341 - val_accuracy: 0.3731\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.7900 - accuracy: 0.3921 - val_loss: 1.8746 - val_accuracy: 0.3535\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.7937 - accuracy: 0.3892 - val_loss: 1.8409 - val_accuracy: 0.3560\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.7920 - accuracy: 0.3886 - val_loss: 2.0390 - val_accuracy: 0.3340\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.7814 - accuracy: 0.3954 - val_loss: 1.8968 - val_accuracy: 0.3537\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.7822 - accuracy: 0.3959 - val_loss: 1.7979 - val_accuracy: 0.3864\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.7832 - accuracy: 0.3970 - val_loss: 1.8849 - val_accuracy: 0.3581\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.7783 - accuracy: 0.3940 - val_loss: 1.8979 - val_accuracy: 0.3415\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.7750 - accuracy: 0.3975 - val_loss: 1.8570 - val_accuracy: 0.3821\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb47820f760>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Multi Layer FCNN Model"
      ],
      "metadata": {
        "id": "ykhQi-1xl9b7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are preprocessing the data by dividing it by 255 to scale the pixel values to the range [0, 1]. We are also converting the integer class labels to one-hot encoded vectors using the to_categorical function.\n",
        "\n",
        "We are then adding a two Conv2D layer to extract features from the images, each followed by a MaxPooling2D layer to reduce the spatial dimension of the data and to increase the robustness of the model by reducing the number of parameters.\n",
        "Then we are flattening the output of the convolutional layers and passing it through a fully connected layer with 128 units and relu activation function.\n",
        "Finally, we are passing the output of the fully connected layer through a final dense layer with 10 units and a softmax activation function. The softmax activation function is used for multi-class classification problem. This layer will output a probability distribution over the 10 classes.\n",
        "\n",
        "We are then compiling the model using the compile method. We need to specify the optimizer that we want to use to update the model's weights during training, as well as the loss function that we want to minimize. In this case, we are using the Adam optimizer and categorical_cross"
      ],
      "metadata": {
        "id": "N_GD3beYnS2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# # Load the CIFAR-10 dataset\n",
        "# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# # Preprocess the data\n",
        "# x_train = x_train.astype('float32') / 255\n",
        "# x_test = x_test.astype('float32') / 255\n",
        "# y_train = to_categorical(y_train)\n",
        "# y_test = to_categorical(y_test)\n",
        "\n",
        "# Define the model\n"
      ],
      "metadata": {
        "id": "71LKeXc9l74z"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=x_train.shape[1:]))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(units=10, activation='softmax'))"
      ],
      "metadata": {
        "id": "hUoK5-Qummfa"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "JYNNfQHvl7tr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sss3qQgll7hL",
        "outputId": "0d759c6f-1d53-4f3c-f1fe-f19273cea66e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4097 - accuracy: 0.4949 - val_loss: 1.1516 - val_accuracy: 0.5898\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0594 - accuracy: 0.6271 - val_loss: 1.0434 - val_accuracy: 0.6306\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9307 - accuracy: 0.6749 - val_loss: 0.9826 - val_accuracy: 0.6556\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8332 - accuracy: 0.7085 - val_loss: 0.9128 - val_accuracy: 0.6865\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7523 - accuracy: 0.7364 - val_loss: 0.9026 - val_accuracy: 0.6914\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6796 - accuracy: 0.7633 - val_loss: 0.8874 - val_accuracy: 0.7019\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6124 - accuracy: 0.7854 - val_loss: 0.9150 - val_accuracy: 0.7025\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5516 - accuracy: 0.8065 - val_loss: 0.9020 - val_accuracy: 0.7053\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4924 - accuracy: 0.8271 - val_loss: 0.9700 - val_accuracy: 0.7010\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4412 - accuracy: 0.8448 - val_loss: 1.0043 - val_accuracy: 0.7047\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb478205af0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Deep FCNN"
      ],
      "metadata": {
        "id": "Z7AvJzU2prC9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have created a deep FCNN by adding multiple dense layers, each layer have more number of units than the previous one, this increases the model's capacity and allows it to learn more complex representations of the data. I have also added multiple convolution."
      ],
      "metadata": {
        "id": "duZZehDglxbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=x_train.shape[1:]))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dense(units=256, activation='relu'))\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(units=10, activation='softmax'))"
      ],
      "metadata": {
        "id": "dUoFj07SpqiE"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "VTkTnHKmpxVz"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=32, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "totj2cKapy3B",
        "outputId": "d8c7bc73-b30e-4f95-e1ed-6c2c3cb48734"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5065 - accuracy: 0.4475 - val_loss: 1.2187 - val_accuracy: 0.5600\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.0963 - accuracy: 0.6109 - val_loss: 1.1417 - val_accuracy: 0.6162\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.9326 - accuracy: 0.6734 - val_loss: 0.9277 - val_accuracy: 0.6785\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.8084 - accuracy: 0.7144 - val_loss: 0.9123 - val_accuracy: 0.6825\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.7046 - accuracy: 0.7509 - val_loss: 0.9311 - val_accuracy: 0.6826\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.6248 - accuracy: 0.7801 - val_loss: 0.9366 - val_accuracy: 0.6954\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5386 - accuracy: 0.8109 - val_loss: 0.9119 - val_accuracy: 0.7044\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4608 - accuracy: 0.8373 - val_loss: 1.0579 - val_accuracy: 0.6819\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4014 - accuracy: 0.8586 - val_loss: 1.0664 - val_accuracy: 0.6911\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3368 - accuracy: 0.8802 - val_loss: 1.1532 - val_accuracy: 0.6979\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2844 - accuracy: 0.8986 - val_loss: 1.2078 - val_accuracy: 0.6990\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2497 - accuracy: 0.9129 - val_loss: 1.3343 - val_accuracy: 0.6937\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2189 - accuracy: 0.9225 - val_loss: 1.3675 - val_accuracy: 0.6969\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1935 - accuracy: 0.9328 - val_loss: 1.4849 - val_accuracy: 0.6824\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1746 - accuracy: 0.9386 - val_loss: 1.5384 - val_accuracy: 0.6856\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1617 - accuracy: 0.9455 - val_loss: 1.5940 - val_accuracy: 0.6853\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1505 - accuracy: 0.9493 - val_loss: 1.6828 - val_accuracy: 0.6954\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1380 - accuracy: 0.9523 - val_loss: 1.6379 - val_accuracy: 0.6897\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1361 - accuracy: 0.9547 - val_loss: 1.8062 - val_accuracy: 0.6919\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1205 - accuracy: 0.9592 - val_loss: 1.8228 - val_accuracy: 0.6885\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb363a12a00>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cross Validation Score\n",
        "5-fold cross validation is a method for evaluating the performance of a machine learning model by dividing the data into 5 parts (folds), training the model on 4 parts and evaluating it on the fifth part. This process is repeated 5 times, each time with a different fifth part as the evaluation set. This way, the model is trained and evaluated on different subsets of the data, which gives a more robust estimate of its performance.\n",
        "\n",
        "The main advantage of 5-fold cross validation is that it allows you to use most of the data for both training and testing, which can lead to more reliable estimates of the model's performance. Also, it is a good practice to use cross-validation rather than using the traditional train-test split, as it gives a better estimate of the model's performance on unseen data."
      ],
      "metadata": {
        "id": "Kr6VPMCLm1KW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "metadata": {
        "id": "zc02GhZgtQDm"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model as you created it before\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=x_train.shape[1:]))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=512, activation='relu'))\n",
        "    model.add(Dense(units=256, activation='relu'))\n",
        "    model.add(Dense(units=128, activation='relu'))\n",
        "    model.add(Dense(units=10, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "QfTkb9X2vrSR"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the k-fold cross-validator\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "zhyWvH3MtZXS"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the wrapper\n",
        "model_wrapper = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n",
        "# Get the cross-validation scores\n",
        "scores = cross_val_score(model_wrapper, x_train, y_train, cv=kfold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDnHZQCltZNm",
        "outputId": "c5ad8d61-2d25-4bbc-82af-cf1180330921"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-3e613f8d7bf2>:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model_wrapper = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gives a list of the accuracy scores for each fold and the mean and standard deviation of the scores. The mean accuracy is the average accuracy over all the folds, and the standard deviation is a measure of how much the accuracy varies between the different folds."
      ],
      "metadata": {
        "id": "mGGERZMqmStx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the mean and standard deviation of the scores\n",
        "print(\"Cross-validation scores: {}\".format(scores))\n",
        "print(\"Mean accuracy: {:.2f}%\".format(scores.mean()*100))\n",
        "print(\"Standard deviation: {:.2f}%\".format(scores.std()*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_Xr5REOtfPD",
        "outputId": "d464726b-6ba4-4b35-b5f5-40aeac853cec"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.68709999 0.68000001 0.67500001 0.69260001 0.68089998]\n",
            "Mean accuracy: 68.31%\n",
            "Standard deviation: 0.61%\n"
          ]
        }
      ]
    }
  ]
}